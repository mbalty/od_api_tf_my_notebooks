{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.builders import model_builder\n",
    "from google.protobuf import text_format\n",
    "import tensorflow as tf\n",
    "from object_detection.protos import model_pb2\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN"
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'prod_faster_rcnn_resnet50_coco'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28'\n",
    "\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph_new.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "test_image_path = \"/home/wc-gpu/MasterThesis/session_data/122923_testing\"\n",
    "# test_image_path = \"/Users/mbaltac/Home/MasterThesis/MasterThesis/labeled_images_shopping_sessions/labeled/122923_testing\"\n",
    "TEST_IMAGE_PATHS = sorted([os.path.join(test_image_path, f) for f in os.listdir(test_image_path) if f.endswith(\"jpg\")])\n",
    "\n",
    "\n",
    "# TEST_IMAGE_PATHS = [TEST_IMAGE_PATHS[0], TEST_IMAGE_PATHS[0]]\n",
    "\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (18, 12)\n",
    "\n",
    "SESSIONS_PATH = \"/home/wc-gpu/storage4tb/session_data_thesis/sessions160000_165000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ai8pLZZWKMS"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KILYnwR5WKMS"
   },
   "outputs": [],
   "source": [
    "# opener = urllib.request.URLopener()\n",
    "# opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "# tar_file = tarfile.open(MODEL_FILE)\n",
    "# for file in tar_file.getmembers():\n",
    "#   file_name = os.path.basename(file.name)\n",
    "#   if 'frozen_inference_graph.pb' in file_name:\n",
    "#     tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default():\n",
    "#   od_graph_def = tf.GraphDef()\n",
    "#   with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "#     serialized_graph = fid.read()\n",
    "#     od_graph_def.ParseFromString(serialized_graph)\n",
    "#     tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image):\n",
    "    with tf.Session(config=tf_config) as sess:\n",
    "\n",
    "      # Get handles to input and output tensors\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = [(op.name, output.name, output.shape) for op in ops for output in op.outputs]\n",
    "        with open(\"bla_log.log\",\"w+\") as f:\n",
    "            f.write(\"\\n\".join([str(a) for a in all_tensor_names]))\n",
    "        tensor_dict = {}\n",
    "    #     for key in [\n",
    "    #       'num_detections', 'detection_boxes', 'detection_scores',\n",
    "    #       'detection_classes', 'detection_masks'\n",
    "    #     ]:\n",
    "    #         tensor_name = key + ':0'\n",
    "    #         if tensor_name in all_tensor_names:\n",
    "    #             tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "    #               tensor_name)\n",
    "    #     if 'detection_masks' in tensor_dict:\n",
    "    #         # The following processing is only for single image\n",
    "    #         detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "    #         detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "    #         # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "    #         real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "    #         detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "    #         detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "    #         detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "    #             detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "    #         detection_masks_reframed = tf.cast(\n",
    "    #             tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "    #         # Follow the convention by adding back the batch dimension\n",
    "    #         tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "    #             detection_masks_reframed, 0)\n",
    "        features = tf.get_default_graph().get_tensor_by_name(\n",
    "            'FirstStageFeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/Relu:0')\n",
    "\n",
    "        tensor_dict['features'] = tf.expand_dims(features, 0)\n",
    "\n",
    "\n",
    "\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "        # Run inference\n",
    "        output_dict = sess.run(tensor_dict, \n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "        # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    #     output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    #     output_dict['detection_classes'] = output_dict[\n",
    "    #       'detection_classes'][0].astype(np.uint8)\n",
    "    #     output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    #     output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    #     if 'detection_masks' in output_dict:\n",
    "    #         output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164413 55\n",
      "164398 56\n",
      "164384 82\n",
      "164378 45\n",
      "164377 50\n",
      "164375 45\n",
      "164372 46\n",
      "164349 54\n",
      "164328 47\n",
      "164325 63\n",
      "164313 57\n",
      "164305 79\n",
      "164303 80\n",
      "164280 48\n",
      "164265 45\n",
      "164244 46\n",
      "164233 75\n",
      "164230 56\n",
      "164224 58\n",
      "164216 115\n",
      "164204 83\n",
      "164194 57\n",
      "164172 45\n",
      "164168 56\n",
      "164155 60\n",
      "164154 86\n",
      "164142 57\n",
      "164141 46\n",
      "164140 54\n",
      "164136 50\n",
      "164135 47\n",
      "164122 62\n",
      "164117 48\n",
      "164102 78\n",
      "164098 114\n",
      "164085 55\n",
      "164079 51\n",
      "164065 93\n",
      "164055 49\n",
      "164051 45\n",
      "164050 56\n",
      "164043 67\n",
      "164042 47\n",
      "164031 50\n",
      "164030 61\n",
      "164025 47\n",
      "164022 47\n",
      "164020 49\n",
      "164017 66\n",
      "164004 56\n",
      "164002 54\n",
      "163995 70\n",
      "163989 60\n",
      "163952 51\n",
      "163935 61\n",
      "163927 52\n",
      "163922 49\n",
      "163918 48\n",
      "163915 48\n",
      "163908 53\n",
      "163894 50\n",
      "163893 49\n",
      "163888 55\n",
      "163882 46\n",
      "163873 49\n",
      "163871 55\n",
      "163868 71\n",
      "163866 59\n",
      "163856 62\n",
      "163855 63\n",
      "163851 56\n",
      "163844 61\n",
      "163834 89\n",
      "163832 48\n",
      "163830 65\n",
      "163822 128\n",
      "163812 55\n",
      "163801 45\n",
      "163797 57\n",
      "163795 61\n",
      "163791 75\n",
      "163786 59\n",
      "163767 60\n",
      "163761 50\n",
      "163759 63\n",
      "162783 53\n",
      "162782 66\n",
      "162781 68\n",
      "162778 59\n",
      "162773 79\n",
      "162772 45\n",
      "162769 46\n",
      "162766 84\n",
      "162761 133\n",
      "162758 69\n",
      "162746 57\n",
      "162744 78\n",
      "162743 47\n",
      "162741 96\n",
      "162739 78\n",
      "162737 60\n",
      "162727 55\n",
      "162725 45\n",
      "162722 56\n",
      "162720 61\n",
      "162718 50\n",
      "162711 51\n",
      "162706 47\n",
      "162705 53\n",
      "162704 59\n",
      "162702 57\n",
      "162693 62\n",
      "162689 49\n",
      "162686 51\n",
      "162680 46\n",
      "162675 102\n",
      "161677 92\n",
      "161674 57\n",
      "161668 46\n",
      "161665 75\n",
      "161662 60\n",
      "161659 50\n",
      "161651 46\n",
      "161648 52\n",
      "161647 92\n",
      "161642 58\n",
      "161634 46\n",
      "161632 54\n",
      "161630 47\n",
      "161612 66\n",
      "161611 90\n",
      "161604 51\n",
      "161602 61\n",
      "161597 74\n",
      "161595 54\n",
      "161593 92\n",
      "161587 45\n",
      "161584 143\n",
      "161579 66\n",
      "161578 62\n",
      "161572 52\n",
      "161561 51\n",
      "161559 46\n",
      "161558 83\n",
      "161557 50\n",
      "161554 76\n",
      "161552 53\n",
      "161550 72\n",
      "161549 45\n",
      "161544 60\n",
      "161543 48\n",
      "161541 77\n",
      "161539 74\n",
      "161536 57\n",
      "161522 63\n",
      "161519 46\n",
      "161515 62\n",
      "161511 56\n",
      "161505 45\n",
      "161494 46\n",
      "161492 47\n",
      "161479 51\n",
      "161477 55\n",
      "161469 73\n",
      "161462 89\n",
      "161448 49\n",
      "161441 106\n",
      "161426 51\n",
      "161422 50\n",
      "161395 50\n",
      "161379 59\n",
      "161377 105\n",
      "161376 70\n",
      "161374 76\n",
      "161369 69\n",
      "161366 70\n",
      "161360 45\n",
      "161353 52\n",
      "161347 57\n",
      "161345 66\n",
      "161337 61\n",
      "161328 48\n",
      "161317 72\n",
      "161313 63\n",
      "161309 75\n",
      "161302 55\n",
      "161298 54\n",
      "161296 47\n",
      "161294 77\n",
      "161291 45\n",
      "161277 66\n",
      "161265 46\n",
      "161261 46\n",
      "161260 54\n",
      "161254 68\n",
      "161252 55\n",
      "161243 50\n",
      "161239 45\n",
      "161220 48\n",
      "161219 64\n",
      "161209 57\n",
      "161198 57\n",
      "161197 55\n",
      "161196 83\n",
      "161195 71\n",
      "161192 50\n",
      "161188 46\n",
      "161187 74\n",
      "161185 64\n",
      "161179 55\n",
      "161176 61\n",
      "161160 105\n",
      "161159 52\n",
      "161156 51\n",
      "161155 65\n",
      "161150 50\n",
      "161144 47\n",
      "161125 49\n",
      "161122 67\n",
      "161108 59\n",
      "161104 63\n",
      "161095 79\n",
      "161084 60\n",
      "161069 48\n",
      "161067 69\n",
      "161066 60\n",
      "161057 48\n",
      "161053 71\n",
      "161052 83\n",
      "161051 53\n",
      "161050 54\n",
      "161045 79\n",
      "161041 46\n",
      "161034 72\n",
      "161027 69\n",
      "161026 68\n",
      "161023 51\n",
      "161022 77\n",
      "161021 88\n",
      "161017 64\n",
      "161010 100\n",
      "161006 48\n",
      "161004 63\n",
      "161001 166\n",
      "161000 72\n",
      "160999 64\n",
      "160998 62\n",
      "160997 79\n",
      "160996 56\n",
      "160993 72\n",
      "160985 119\n",
      "160977 63\n",
      "160976 61\n",
      "160974 63\n",
      "160973 61\n",
      "160967 48\n",
      "160955 49\n",
      "160954 54\n",
      "160950 63\n",
      "160947 75\n",
      "160935 76\n",
      "160929 47\n",
      "160924 65\n",
      "160915 91\n",
      "160913 63\n",
      "160905 51\n",
      "160903 84\n",
      "160901 62\n",
      "160899 45\n",
      "160897 68\n",
      "160894 63\n",
      "160893 73\n",
      "160885 45\n",
      "160881 47\n",
      "160867 54\n",
      "160864 53\n",
      "160863 126\n",
      "160848 74\n",
      "160837 61\n",
      "160833 76\n",
      "160831 52\n",
      "160830 56\n",
      "160827 63\n",
      "160820 74\n",
      "160818 65\n",
      "160805 119\n",
      "160802 77\n",
      "160798 83\n",
      "160794 61\n",
      "160786 61\n",
      "160783 53\n",
      "160781 58\n",
      "160778 46\n",
      "160775 86\n",
      "160755 75\n",
      "160751 60\n",
      "160750 46\n",
      "160748 56\n",
      "160745 60\n",
      "160740 112\n",
      "160738 63\n",
      "160736 49\n",
      "160725 51\n",
      "160722 72\n",
      "160719 55\n",
      "160708 45\n",
      "160704 119\n",
      "160703 93\n",
      "160699 49\n",
      "160692 57\n",
      "160690 66\n",
      "160685 75\n",
      "160679 53\n",
      "160677 54\n",
      "160670 47\n",
      "160667 73\n",
      "160665 69\n",
      "160663 64\n",
      "160653 61\n",
      "160650 77\n",
      "160610 46\n",
      "160605 49\n",
      "160602 58\n",
      "160564 61\n",
      "160556 49\n",
      "160552 57\n",
      "160538 102\n",
      "160534 55\n",
      "160516 58\n",
      "160446 76\n",
      "160445 79\n",
      "160428 59\n",
      "160390 64\n",
      "160368 48\n",
      "160330 51\n",
      "160329 49\n",
      "160327 62\n",
      "160316 49\n",
      "160279 49\n",
      "160273 59\n",
      "160272 50\n",
      "160241 46\n",
      "160229 68\n",
      "160200 60\n",
      "160156 48\n",
      "160151 53\n",
      "160139 49\n",
      "160124 59\n",
      "160113 59\n",
      "160087 70\n",
      "160074 47\n",
      "160053 47\n",
      "160044 51\n",
      "160037 74\n",
      "160020 61\n",
      "160017 55\n",
      "160014 80\n",
      "160012 51\n",
      "160006 44\n",
      "123429 22\n",
      "123424 26\n",
      "123419 11\n",
      "123418 13\n",
      "123416 43\n",
      "123413 11\n",
      "123409 27\n",
      "123407 48\n",
      "123403 58\n",
      "123401 14\n",
      "123392 18\n",
      "123390 6\n",
      "123382 39\n",
      "123381 40\n",
      "123379 15\n",
      "123375 17\n",
      "123374 19\n",
      "123372 15\n",
      "123360 41\n",
      "123358 6\n",
      "123356 41\n",
      "123355 16\n",
      "123345 15\n",
      "123330 34\n",
      "123329 19\n",
      "123307 8\n",
      "123303 8\n",
      "123300 7\n",
      "123292 10\n",
      "123291 12\n",
      "123288 22\n",
      "123282 32\n",
      "123272 10\n",
      "123271 24\n",
      "123262 4\n",
      "123238 33\n",
      "123234 32\n",
      "123229 1\n",
      "123225 27\n",
      "123221 15\n",
      "123216 22\n",
      "123213 7\n",
      "123185 20\n",
      "123179 21\n",
      "123178 15\n",
      "123176 34\n",
      "123172 23\n",
      "123171 28\n",
      "123166 15\n",
      "123164 27\n",
      "123161 23\n",
      "123156 27\n",
      "123153 41\n",
      "123152 19\n",
      "123137 18\n",
      "123136 33\n",
      "123132 26\n",
      "123123 13\n",
      "123120 27\n",
      "123114 14\n",
      "123113 55\n",
      "123104 16\n",
      "123097 26\n",
      "123092 20\n",
      "123089 23\n",
      "123084 48\n",
      "123082 23\n",
      "123074 35\n",
      "123071 48\n",
      "123051 22\n",
      "123041 22\n",
      "123034 14\n",
      "123028 27\n",
      "123021 13\n",
      "123016 20\n",
      "123010 60\n",
      "123004 8\n",
      "123003 52\n",
      "122997 20\n",
      "122979 41\n",
      "122975 39\n",
      "122973 7\n",
      "122970 55\n",
      "122967 51\n",
      "122963 10\n",
      "122962 25\n",
      "122961 49\n",
      "122959 7\n",
      "122954 12\n",
      "122953 15\n",
      "122949 22\n",
      "122945 13\n",
      "122943 3\n",
      "122938 5\n",
      "122933 9\n",
      "122932 12\n",
      "122931 13\n",
      "122909 54\n",
      "122903 32\n",
      "122901 1\n",
      "122896 34\n",
      "122892 20\n",
      "122890 12\n",
      "122887 12\n",
      "122880 12\n",
      "122874 5\n",
      "122873 7\n",
      "122868 40\n",
      "122862 48\n",
      "122861 40\n",
      "122860 14\n",
      "122858 20\n",
      "122854 5\n",
      "122849 19\n",
      "122848 13\n",
      "122847 14\n",
      "118885 17\n",
      "118863 29\n",
      "118859 49\n",
      "118828 18\n",
      "117687 66\n",
      "117684 80\n",
      "117653 30\n"
     ]
    }
   ],
   "source": [
    "visualize_debug = False\n",
    "\n",
    "features = None\n",
    "total_images = 0\n",
    "sessions = os.listdir(SESSIONS_PATH)\n",
    "actual_sessions = []\n",
    "\n",
    "for session in sorted(sessions, reverse=True):\n",
    "    try:\n",
    "        a = int(session)\n",
    "        session_path = os.path.join(SESSIONS_PATH, session)\n",
    "        \n",
    "        if os.path.exists(os.path.join(session_path, \"annotations\")):\n",
    "            actual_sessions.append(session)\n",
    "            images = [f for f in os.listdir(session_path) if f.endswith(\".jpg\")]\n",
    "            total_images += len(images)\n",
    "            print (session, len(images))\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "progress = 0\n",
    "\n",
    "processed = 0\n",
    "time_avg = 0\n",
    "\n",
    "outputs = []\n",
    "\n",
    "log= open(\"feature_extraction_new.log\",\"w+\")\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "    for session in sorted(actual_sessions, reverse=True):\n",
    "        session_path = os.path.join(SESSIONS_PATH, session)\n",
    "\n",
    "        images = [f for f in os.listdir(session_path) if f.endswith(\".jpg\")]\n",
    "        for image_fname in sorted(images):\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                has_processed = False\n",
    "                features_path = os.path.join(session_path, \"features\")\n",
    "                if not os.path.exists(os.path.join(features_path, image_fname+\".feature.prod.new.better.small\")):\n",
    "\n",
    "                    image_path = os.path.join(session_path, image_fname)\n",
    "\n",
    "                    image = Image.open(image_path)\n",
    "                    image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "                    output_dict = run_inference_for_single_image(image_np)\n",
    "                    features = output_dict[\"features\"][0]\n",
    "                    break\n",
    "                    features_path = os.path.join(session_path, \"features\")\n",
    "                    if not os.path.exists(features_path):\n",
    "                        os.makedirs(features_path)\n",
    "\n",
    "                    with open(os.path.join(features_path, image_fname+\".feature.prod.new.better.small\"), \"wb\") as f:\n",
    "                        np.save(f, features)\n",
    "\n",
    "                    total_time = time_avg * processed\n",
    "                    processed += 1\n",
    "                    has_processed = True\n",
    "\n",
    "\n",
    "\n",
    "                if visualize_debug:\n",
    "                    outputs.append(output_dict)\n",
    "                    # Visualization of the results of a detection.\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                      image_np,\n",
    "                      output_dict['detection_boxes'],\n",
    "                      output_dict['detection_classes'],\n",
    "                      output_dict['detection_scores'],\n",
    "                      category_index,\n",
    "                      instance_masks=output_dict.get('detection_masks'),\n",
    "                      use_normalized_coordinates=True,\n",
    "                      line_thickness=5,\n",
    "                      min_score_thresh=.3)\n",
    "                    plt.figure(figsize=IMAGE_SIZE)\n",
    "                    plt.imshow(image_np)\n",
    "\n",
    "\n",
    "                    slc = features[0][:,:,5]\n",
    "                    slc *= 255.0/slc.max()  \n",
    "\n",
    "                    img = Image.fromarray(slc)\n",
    "                    img = img.convert('RGB')\n",
    "\n",
    "                    plt.figure(figsize=IMAGE_SIZE)\n",
    "                    plt.imshow(img)\n",
    "\n",
    "            except Exception as ex:\n",
    "                print (\"IMAGE \", image_fname)\n",
    "                print (str(ex))\n",
    "\n",
    "\n",
    "            t1 = time.time()\n",
    "\n",
    "            total = t1-t0\n",
    "\n",
    "            if has_processed:\n",
    "                time_avg = (total_time + total) / processed\n",
    "\n",
    "\n",
    "            log_text = \" \".join([\"progress \", session, \":\", str(progress / total_images), \n",
    "                                 str(progress), str(total_images)])\n",
    "            log_text += \" | \"\n",
    "\n",
    "            log_text += \"\".join([\"process time \", str(total)])\n",
    "            log_text += \" | \"\n",
    "            log_text += \"\".join([\" time passed: \", str(time_avg*processed / 3600) ,\" h, remaining: \", str(time_avg* (total_images - progress) / 3600), \" h\"])\n",
    "            \n",
    "            \n",
    "            print (log_text, end=\"                                       \\r\")\n",
    "            log.write(log_text + \"\\r\\n\")\n",
    "\n",
    "            progress += 1\n",
    "\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
