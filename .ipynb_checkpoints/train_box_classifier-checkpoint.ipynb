{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "from deep_tools.training_callbacks import *\n",
    "import math\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "import pickle as pkl\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "\n",
    "    \"\"\"\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(2048, input_dim=4096, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # model.add(Dense(2048, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "learning_rate = 0.001\n",
    "# decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=0, nesterov=False)\n",
    "model.compile(loss=binary_focal_loss(), optimizer=\"adam\", metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_callback = TrainingAccuracyPlotter()\n",
    "loss_plotter = TrainingLossPlotter()\n",
    "time_plotter = TimeLogCallback()\n",
    "\n",
    "\n",
    "checkpoint = checkpoint_classification_callback(\n",
    "    checkpoint_path=\"/home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint\", \n",
    "    monitor='val_acc',\n",
    "    save_best_only=True)\n",
    "callbacks = [time_plotter, acc_callback, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\n",
    "    \"/home/wc-gpu/storage4tb/session_data_thesis/sessions160000_165000/\"+\n",
    "    \"dataset_prod_new_model_binary_1prev_session_split_bla.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdict = data[0]\n",
    "Ydict = data[1]\n",
    "sessions = Xdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random.sample(sessions, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = set(['162737', '123071', '123229', '164085', '160827', '163832', '161552', '118828', '161441', '118859', '123178', '160685', '122874', '122949', '161209', '161612', '123051', '163888', '160037', '161185', '161069', '161095', '123082', '160665', '160977'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.34848404,  4.51842308,  3.54128098, ...,  2.98927402,\n",
       "         2.58149433, 20.06006622],\n",
       "       [ 5.53672314,  5.20862675,  1.70428252, ...,  2.98927402,\n",
       "         2.58149433, 20.06006622],\n",
       "       [ 4.73910904,  4.39916229,  0.        , ...,  3.9010787 ,\n",
       "         2.31463337, 19.73424149],\n",
       "       ...,\n",
       "       [ 7.5994482 , 17.74806023,  1.04462659, ...,  9.66398335,\n",
       "         5.2741127 ,  8.686903  ],\n",
       "       [ 5.55770493,  7.91496468,  1.07404649, ...,  8.56598663,\n",
       "         4.93575287,  9.08606911],\n",
       "       [ 1.24807024, 15.14763737,  5.08564758, ...,  8.56598663,\n",
       "         4.93575287,  9.08606911]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdict[\"162737\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "xval = []\n",
    "ytrain = []\n",
    "yval = []\n",
    "\n",
    "\n",
    "for s in sessions:\n",
    "    if s in val:\n",
    "        xval.extend(Xdict[s])\n",
    "        yval.extend(Ydict[s])\n",
    "    else:\n",
    "        xtrain.extend(Xdict[s])\n",
    "        ytrain.extend(Ydict[s])\n",
    "\n",
    "xtrain = np.asarray(xtrain)\n",
    "xval = np.asarray(xval)\n",
    "ytrain = np.asarray(ytrain)\n",
    "yval = np.asarray(yval)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xtrain\n",
    "y = ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x[perm]\n",
    "y =y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42148"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(y)\n",
    "                                               ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = [ 0.001,  1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = [ 0.01,  0.9,  0.9, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18626"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mn = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0)\n",
    "    x = (x - mn)/std\n",
    "    return mn, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = normalize(x)\n",
    "# b = normalize(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mn_std.pkl\", \"wb\") as f:\n",
    "    pkl.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = np.where(y == 0)[0]\n",
    "negatives = negatives[np.random.choice(negatives.shape[0], len(np.where(y==1)[0]), replace=False)]\n",
    "positives = np.where(y != 0)[0]\n",
    "idxs = np.concatenate([negatives, positives])\n",
    "np.random.shuffle(idxs)\n",
    "# x[np.where(x == 0)[0]] = .1\n",
    "x = x[idxs]\n",
    "y = y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xval = x[:3000]\n",
    "# yval = y[:3000]\n",
    "# x = x[3000:]\n",
    "# y = y[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y, num_classes=None, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37252 samples, validate on 3158 samples\n",
      "Epoch 1/100\n",
      "37252/37252 [==============================] - 2s 50us/step - loss: 45.7889 - acc: 0.7188 - val_loss: 42.0032 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77644, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch01-val_acc0.78-val_loss42.00.hdf5\n",
      "Epoch 2/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 19.0084 - acc: 0.8233 - val_loss: 47.5288 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.77644\n",
      "Epoch 3/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 14.3615 - acc: 0.8707 - val_loss: 43.8820 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77644 to 0.77834, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch03-val_acc0.78-val_loss43.88.hdf5\n",
      "Epoch 4/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 10.0133 - acc: 0.9124 - val_loss: 71.8185 - val_acc: 0.6773\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77834\n",
      "Epoch 5/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 7.2391 - acc: 0.9398 - val_loss: 101.9848 - val_acc: 0.6514\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77834\n",
      "Epoch 6/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 5.7343 - acc: 0.9550 - val_loss: 49.4370 - val_acc: 0.7973\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.77834 to 0.79734, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch06-val_acc0.80-val_loss49.44.hdf5\n",
      "Epoch 7/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 4.7997 - acc: 0.9641 - val_loss: 225.6450 - val_acc: 0.5434\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79734\n",
      "Epoch 8/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 3.3324 - acc: 0.9775 - val_loss: 108.7839 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79734\n",
      "Epoch 9/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 2.8009 - acc: 0.9810 - val_loss: 82.3463 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79734\n",
      "Epoch 10/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 2.8394 - acc: 0.9805 - val_loss: 74.7591 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79734\n",
      "Epoch 11/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 2.3626 - acc: 0.9836 - val_loss: 132.7106 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.79734\n",
      "Epoch 12/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 3.1983 - acc: 0.9773 - val_loss: 67.9116 - val_acc: 0.8018\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.79734 to 0.80177, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch12-val_acc0.80-val_loss67.91.hdf5\n",
      "Epoch 13/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 3.6879 - acc: 0.9742 - val_loss: 168.3810 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80177\n",
      "Epoch 14/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 3.2322 - acc: 0.9769 - val_loss: 388.3122 - val_acc: 0.4839\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80177\n",
      "Epoch 15/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 1.9040 - acc: 0.9877 - val_loss: 90.7952 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.80177 to 0.81602, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch15-val_acc0.82-val_loss90.80.hdf5\n",
      "Epoch 16/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 1.9185 - acc: 0.9885 - val_loss: 252.2303 - val_acc: 0.6254\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81602\n",
      "Epoch 17/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 2.1614 - acc: 0.9861 - val_loss: 72.2949 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.81602\n",
      "Epoch 18/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 1.2435 - acc: 0.9918 - val_loss: 90.6946 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.81602\n",
      "Epoch 19/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.4767 - acc: 0.9975 - val_loss: 69.0054 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.81602 to 0.81919, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch19-val_acc0.82-val_loss69.01.hdf5\n",
      "Epoch 20/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.1701 - acc: 0.9994 - val_loss: 168.5431 - val_acc: 0.7571\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.81919\n",
      "Epoch 21/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.1444 - acc: 0.9996 - val_loss: 90.4709 - val_acc: 0.8376\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.81919 to 0.83756, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch21-val_acc0.84-val_loss90.47.hdf5\n",
      "Epoch 22/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.2478 - acc: 0.9995 - val_loss: 98.3795 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.83756\n",
      "Epoch 23/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.8112 - acc: 0.9967 - val_loss: 150.1542 - val_acc: 0.7818\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.83756\n",
      "Epoch 24/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 2.4867 - acc: 0.9840 - val_loss: 217.1152 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.83756\n",
      "Epoch 25/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 5.8688 - acc: 0.9631 - val_loss: 555.2930 - val_acc: 0.4696\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83756\n",
      "Epoch 26/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 4.7058 - acc: 0.9645 - val_loss: 112.8252 - val_acc: 0.7894\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83756\n",
      "Epoch 27/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 2.7465 - acc: 0.9824 - val_loss: 88.8775 - val_acc: 0.7796\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83756\n",
      "Epoch 28/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.8252 - acc: 0.9949 - val_loss: 63.0324 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83756\n",
      "Epoch 29/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.3361 - acc: 0.9987 - val_loss: 139.5580 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83756\n",
      "Epoch 30/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.1285 - acc: 0.9999 - val_loss: 74.0065 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.83756 to 0.83914, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch30-val_acc0.84-val_loss74.01.hdf5\n",
      "Epoch 31/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0537 - acc: 0.9999 - val_loss: 78.3733 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.83914 to 0.85022, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch31-val_acc0.85-val_loss78.37.hdf5\n",
      "Epoch 32/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 89.3434 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.85022 to 0.85054, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch32-val_acc0.85-val_loss89.34.hdf5\n",
      "Epoch 33/100\n",
      "37252/37252 [==============================] - 1s 30us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 87.8374 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.85054\n",
      "Epoch 34/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0271 - acc: 0.9999 - val_loss: 86.4513 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.85054 to 0.85370, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch34-val_acc0.85-val_loss86.45.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 90.4414 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85370\n",
      "Epoch 36/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 91.8481 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85370\n",
      "Epoch 37/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 91.9241 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.85370 to 0.85497, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch37-val_acc0.85-val_loss91.92.hdf5\n",
      "Epoch 38/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 95.6069 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.85497\n",
      "Epoch 39/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 94.2629 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.85497\n",
      "Epoch 40/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0526 - acc: 0.9999 - val_loss: 110.1854 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85497\n",
      "Epoch 41/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 94.7654 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.85497\n",
      "Epoch 42/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 0.0492 - acc: 0.9999 - val_loss: 121.0560 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85497\n",
      "Epoch 43/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0319 - acc: 0.9999 - val_loss: 100.6195 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.85497\n",
      "Epoch 44/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 99.1280 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.85497\n",
      "Epoch 45/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0242 - acc: 0.9999 - val_loss: 104.1013 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.85497\n",
      "Epoch 46/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 97.7904 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.85497\n",
      "Epoch 47/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 102.1867 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.85497\n",
      "Epoch 48/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 99.5985 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.85497 to 0.85592, saving model to /home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/2019-04-08weights-epoch48-val_acc0.86-val_loss99.60.hdf5\n",
      "Epoch 49/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 104.3769 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.85592\n",
      "Epoch 50/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0251 - acc: 0.9999 - val_loss: 107.9644 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.85592\n",
      "Epoch 51/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 135.8638 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.85592\n",
      "Epoch 52/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.1472 - acc: 0.9997 - val_loss: 110.9674 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.85592\n",
      "Epoch 53/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 8.1371 - acc: 0.9563 - val_loss: 280.3243 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.85592\n",
      "Epoch 54/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 11.5611 - acc: 0.9075 - val_loss: 237.0832 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.85592\n",
      "Epoch 55/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 3.5188 - acc: 0.9720 - val_loss: 103.5181 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.85592\n",
      "Epoch 56/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 1.2613 - acc: 0.9919 - val_loss: 67.6595 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.85592\n",
      "Epoch 57/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.7209 - acc: 0.9962 - val_loss: 67.1438 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.85592\n",
      "Epoch 58/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.6163 - acc: 0.9977 - val_loss: 90.4671 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.85592\n",
      "Epoch 59/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.2997 - acc: 0.9987 - val_loss: 100.0690 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85592\n",
      "Epoch 60/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.1824 - acc: 0.9996 - val_loss: 88.0221 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.85592\n",
      "Epoch 61/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0487 - acc: 1.0000 - val_loss: 96.7242 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.85592\n",
      "Epoch 62/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 101.7564 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.85592\n",
      "Epoch 63/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 105.8625 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.85592\n",
      "Epoch 64/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 102.4772 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.85592\n",
      "Epoch 65/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 106.8549 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.85592\n",
      "Epoch 66/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 112.8954 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.85592\n",
      "Epoch 67/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 0.0668 - acc: 0.9999 - val_loss: 135.9068 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.85592\n",
      "Epoch 68/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0301 - acc: 0.9999 - val_loss: 109.8937 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85592\n",
      "Epoch 69/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0397 - acc: 0.9999 - val_loss: 128.5603 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85592\n",
      "Epoch 70/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0183 - acc: 0.9999 - val_loss: 106.1377 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.85592\n",
      "Epoch 71/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 109.2233 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85592\n",
      "Epoch 72/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 111.3909 - val_acc: 0.8509\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85592\n",
      "Epoch 73/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 111.7241 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85592\n",
      "Epoch 74/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 113.1330 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85592\n",
      "Epoch 75/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 115.8473 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85592\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 114.7349 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85592\n",
      "Epoch 77/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 115.7926 - val_acc: 0.8521\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85592\n",
      "Epoch 78/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 116.1836 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85592\n",
      "Epoch 79/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 116.8753 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85592\n",
      "Epoch 80/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 117.6604 - val_acc: 0.8521\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85592\n",
      "Epoch 81/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 118.4269 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85592\n",
      "Epoch 82/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 120.7438 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.85592\n",
      "Epoch 83/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 120.8642 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.85592\n",
      "Epoch 84/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 120.1514 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.85592\n",
      "Epoch 85/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 123.2963 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.85592\n",
      "Epoch 86/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0202 - acc: 0.9999 - val_loss: 119.9081 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.85592\n",
      "Epoch 87/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 125.5695 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.85592\n",
      "Epoch 88/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 122.9386 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.85592\n",
      "Epoch 89/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0113 - acc: 0.9999 - val_loss: 133.6670 - val_acc: 0.8436\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.85592\n",
      "Epoch 90/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.0953 - acc: 0.9998 - val_loss: 294.8975 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.85592\n",
      "Epoch 91/100\n",
      "37252/37252 [==============================] - 1s 29us/step - loss: 13.6745 - acc: 0.9190 - val_loss: 537.1675 - val_acc: 0.6922\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.85592\n",
      "Epoch 92/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 8.1079 - acc: 0.9362 - val_loss: 67.8599 - val_acc: 0.7587\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.85592\n",
      "Epoch 93/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 2.4943 - acc: 0.9821 - val_loss: 62.4107 - val_acc: 0.8091\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.85592\n",
      "Epoch 94/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.9346 - acc: 0.9949 - val_loss: 62.9840 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.85592\n",
      "Epoch 95/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.3100 - acc: 0.9990 - val_loss: 100.2771 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.85592\n",
      "Epoch 96/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.1798 - acc: 0.9996 - val_loss: 72.9279 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.85592\n",
      "Epoch 97/100\n",
      "37252/37252 [==============================] - 1s 28us/step - loss: 0.3742 - acc: 0.9991 - val_loss: 131.7351 - val_acc: 0.7967\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.85592\n",
      "Epoch 98/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.2425 - acc: 0.9993 - val_loss: 87.8703 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.85592\n",
      "Epoch 99/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.1739 - acc: 0.9997 - val_loss: 125.4678 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.85592\n",
      "Epoch 100/100\n",
      "37252/37252 [==============================] - 1s 27us/step - loss: 0.0861 - acc: 0.9999 - val_loss: 102.3183 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.85592\n"
     ]
    }
   ],
   "source": [
    "hitsory = model.fit(x=x,\n",
    "    y=y_cat, \n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    "    verbose=1, \n",
    "    callbacks=[checkpoint],\n",
    "#     validation_split=0.1, \n",
    "    validation_data=[xval, yval], \n",
    "    shuffle=True, \n",
    "#     class_weight=class_weight, \n",
    "    sample_weight=None, \n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(yval==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/wc-gpu/MasterThesis/models/research/object_detection/box_classification_checkpoint/\"+\n",
    "                  \"2019-04-08weights-epoch48-val_acc0.86-val_loss99.60.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972/972 [==============================] - 0s 33us/step\n"
     ]
    }
   ],
   "source": [
    "a = model.evaluate(xval[w], yval[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(xval) > 0.5).astype(\"int64\").transpose()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Confusion matrix, without normalization\n",
      "[[1923  263]\n",
      " [ 192  780]]\n",
      "Normalized confusion matrix\n",
      "[[0.88 0.12]\n",
      " [0.2  0.8 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c01d36f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b6a283940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(yval, y_pred, classes=np.array([\"same\", \"add\"]),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(yval, y_pred, np.array([\"same\", \"add\"]), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session_path = \"/home/wc-gpu/MasterThesis/session_data/122923_testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.10\n",
    "   drop = 0.8\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "def exp_decay(epoch):\n",
    "   initial_lrate = 0.01\n",
    "   k = 0.1\n",
    "   lrate = initial_lrate * math.exp(-k*epoch)\n",
    "   return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "# lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "# class LossHistory(Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#        self.losses = []\n",
    "#        self.lr = []\n",
    " \n",
    "#     def on_epoch_end(self, batch, logs={}):\n",
    "#        self.losses.append(logs.get(\"val_loss\"))\n",
    "#        self.lr.append(step_decay(len(self.losses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
