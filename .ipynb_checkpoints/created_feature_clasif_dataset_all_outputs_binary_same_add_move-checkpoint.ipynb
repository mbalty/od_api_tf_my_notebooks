{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from math import floor, ceil\n",
    "import time\n",
    "from collections import deque\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_dynamic_input(x, H_out, W_out):\n",
    "    while x.shape[1] < H_out:\n",
    "            x = np.concatenate([x, x], axis=1)\n",
    "    while x.shape[2] < W_out:\n",
    "            x = np.concatenate([x, x], axis=3)\n",
    "    out = None\n",
    "    (N, H, W, C) = x.shape\n",
    "    pool_height = np.zeros((H_out), dtype=\"int32\")\n",
    "    pool_width = np.zeros((W_out), dtype=\"int32\")\n",
    "    \n",
    "    div_h = int(H/H_out)\n",
    "    mod_h = H%H_out\n",
    "    div_w = int(W/W_out)\n",
    "    mod_w = W%W_out\n",
    "    pool_height = pool_height + div_h\n",
    "    pool_width = pool_width + div_w\n",
    "    pool_height[:mod_h] += 1\n",
    "    pool_width[:mod_w] += 1\n",
    "    \n",
    "    out = np.zeros((N, H_out, W_out, C))\n",
    "    for n in range(N):\n",
    "        for h in range(H_out):\n",
    "            for w in range(W_out):\n",
    "                h1 = sum(pool_height[:h])\n",
    "                h2 = h1 + pool_height[h]\n",
    "                w1 = sum(pool_width[:w])\n",
    "                w2 = w1 + pool_width[w]\n",
    "                window = x[n, h1:h2, w1:w2, :]\n",
    "                m = np.max(window, axis=0)\n",
    "                m = np.max(m, axis=0)\n",
    "                out[n,h,w,:] = m\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_and_concat(*args):\n",
    "    size = 0\n",
    "    for arg in args:\n",
    "        size += arg.shape[-1]\n",
    "    final = np.zeros(size*roi_size*roi_size)\n",
    "    arg_size = 0\n",
    "    \n",
    "    i = 0\n",
    "    for arg in args:\n",
    "        max_pool = max_pool_dynamic_input(np.expand_dims(arg, 0), roi_size, roi_size).flatten()\n",
    "        final[i: arg.shape[-1]*roi_size*roi_size+i] = max_pool\n",
    "        i+= arg.shape[-1]*roi_size*roi_size \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_detections_same_class(output_dict, detection_labels, max_iou=.10, max_filtered=20, conf_tesh=.5, rand_select=2):\n",
    "    filtered_idx = []\n",
    "    detections = output_dict[\"detection_boxes\"]\n",
    "    for i in range(len(detections)):\n",
    "        if(output_dict['detection_scores'][i] >= conf_tesh):\n",
    "            detection = detections[i]\n",
    "            add_to_filter = True\n",
    "            for label in detection_labels:\n",
    "                if bb_intersection_over_union(detection, label) > max_iou:\n",
    "                    add_to_filter = False\n",
    "                    break\n",
    "\n",
    "            for fi in filtered_idx:\n",
    "                if bb_intersection_over_union(detection, detections[fi]) > .5:\n",
    "                    add_to_filter = False\n",
    "                    break\n",
    "\n",
    "            if add_to_filter:\n",
    "                filtered_idx.append(i)\n",
    "\n",
    "            if len(filtered_idx) > max_filtered:\n",
    "                break\n",
    "    if len(filtered_idx) > rand_select:\n",
    "        filtered_idx = random.sample(filtered_idx, rand_select)\n",
    "    \n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][filtered_idx]\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'][filtered_idx]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][filtered_idx]\n",
    "    \n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(fpath: str) :\n",
    "    try:\n",
    "        fpath = os.path.abspath(fpath)\n",
    "        tree = ET.parse(fpath)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        img_path = os.path.abspath(os.path.join(os.path.dirname(fpath), \"..\", root.find(\"filename\").text))\n",
    "        img_label = []\n",
    "        size = root.find(\"size\")\n",
    "        width = float(size.find(\"width\").text)\n",
    "        height = float(size.find(\"height\").text)\n",
    "        for child in root.findall(\"object\"):\n",
    "            name = child.find(\"name\").text\n",
    "            if \"add\" in name or \"remove\"in name:\n",
    "                bndbox = child.find(\"bndbox\")\n",
    "                xmin = float(bndbox.find(\"xmin\").text)/width\n",
    "                ymin = float(bndbox.find(\"ymin\").text)/height\n",
    "                xmax = float(bndbox.find(\"xmax\").text)/width\n",
    "                ymax = float(bndbox.find(\"ymax\").text)/height\n",
    "                img_label.append((ymin, xmin, ymax, xmax, name))\n",
    "        return img_label\n",
    "    except Exception as ex:\n",
    "        print (ex)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_detections_create_Ds(detections, detection_labels, max_iou=.3, max_filtered=10, rand_select=2):\n",
    "    filtered_idx = []\n",
    "    for i in range(len(detections)):\n",
    "        detection = detections[i]\n",
    "        add_to_filter = True\n",
    "        for label in detection_labels:\n",
    "            if bb_intersection_over_union(detection, label) > max_iou:\n",
    "                add_to_filter = False\n",
    "                break\n",
    "\n",
    "        for fi in filtered_idx:\n",
    "            if bb_intersection_over_union(detection, detections[fi]) > 0.1:\n",
    "                add_to_filter = False\n",
    "                break\n",
    "\n",
    "        if add_to_filter:\n",
    "            filtered_idx.append(i)\n",
    "\n",
    "        if len(filtered_idx) > max_filtered:\n",
    "            break\n",
    "    if len(filtered_idx) > rand_select:\n",
    "        filtered_idx = random.sample(filtered_idx, rand_select)\n",
    "    \n",
    "    return detections[filtered_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_path = \"/home/wc-gpu/storage4tb/session_data_thesis/sessions160000_165000/\"\n",
    "processed_path = \"/home/wc-gpu/storage4tb/session_data_thesis/sessions160000_165000/processed_sessions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2all = dict()\n",
    "Y2all = dict()\n",
    "X3all = dict()\n",
    "Y3all = dict()\n",
    "c_ses = 0\n",
    "all_ses = len(os.listdir(processed_path))\n",
    "for session in os.listdir(processed_path):\n",
    "    print (\"progress\", session, \"  : \", c_ses / all_ses, \"                   \\r\")\n",
    "    proc_path = os.path.join(processed_path, session)\n",
    "    output_dicts = []\n",
    "    with open(proc_path, \"rb\") as f:\n",
    "        output_dicts = pkl.load(f)[0]\n",
    "    \n",
    "    X2 = []\n",
    "    Y2 = []\n",
    "    X3 = []\n",
    "    Y3 = []\n",
    "    previous_features = None\n",
    "    previous_boxes = None\n",
    "    prev2_features = None\n",
    "    prev2_boxes = None\n",
    "    for output_dict in output_dicts:\n",
    "        try:\n",
    "\n",
    "            image_name = os.path.splitext(output_dict[\"image_path\"].split(\"/\")[-1])[0]\n",
    "            ann_path = os.path.join(sessions_path,session,\"annotations\", image_name + \".xml\")\n",
    "            \n",
    "            annotations = get_labels(ann_path) if os.path.exists(ann_path) else []\n",
    "            output_dict = filter_detections_same_class(output_dict, annotations)\n",
    "\n",
    "            detection_boxes = output_dict[\"detection_boxes\"]\n",
    "            detection_scores = output_dict[\"detection_scores\"]\n",
    "            features = output_dict[\"features\"]\n",
    "            detection_boxes = filter_detections_create_Ds(detection_boxes, annotations)\n",
    "            boxes = (detection_boxes, annotations)\n",
    "#             print (len(detection_boxes), len(annotations))\n",
    "\n",
    "            if previous_features is not None:\n",
    "                for label in boxes[0]:\n",
    "                    box_prev = previous_features[\n",
    "                        floor(label[0]*previous_features.shape[0]):\n",
    "                        ceil(label[2]*previous_features.shape[0]), \n",
    "                        floor(label[1]*previous_features.shape[1]):\n",
    "                        ceil(label[3]*previous_features.shape[1]),:]\n",
    "                    box_cur = features[\n",
    "                        floor(label[0]*features.shape[0]):\n",
    "                        ceil(label[2]*features.shape[0]), \n",
    "                        floor(label[1]*features.shape[1]):\n",
    "                        ceil(label[3]*features.shape[1]),:]\n",
    "\n",
    "                    max_pooled = get_max_and_concat(box_prev, previous_features, box_cur, features)\n",
    "                    X2.append(max_pooled)\n",
    "                    Y2.append(0)\n",
    "\n",
    "#                     if prev2_features is not None:\n",
    "#                         box_prev2 = prev2_features[\n",
    "#                             floor(label[0]*previous_features.shape[0]):\n",
    "#                             ceil(label[2]*previous_features.shape[0]), \n",
    "#                             floor(label[1]*previous_features.shape[1]):\n",
    "#                             ceil(label[3]*previous_features.shape[1]),:]\n",
    "#                         max_pooled = get_max_and_concat(\n",
    "#                             box_prev2, prev2_features,\n",
    "#                             box_prev, previous_features,\n",
    "#                             box_cur, features)\n",
    "#                         X3.append(max_pooled)\n",
    "#                         Y3.append(0)\n",
    "\n",
    "\n",
    "\n",
    "                for label in boxes[1]:\n",
    "                    if \"add\" in label[4] or (\"move\" in label[4] and \"move_from\" not in label[4]):\n",
    "                        box_prev = previous_features[\n",
    "                            floor(label[0]*previous_features.shape[0]):\n",
    "                            ceil(label[2]*previous_features.shape[0]), \n",
    "                            floor(label[1]*previous_features.shape[1]):\n",
    "                            ceil(label[3]*previous_features.shape[1]),:]\n",
    "                        box_cur = features[\n",
    "                            floor(label[0]*features.shape[0]):\n",
    "                            ceil(label[2]*features.shape[0]), \n",
    "                            floor(label[1]*features.shape[1]):\n",
    "                            ceil(label[3]*features.shape[1]),:]\n",
    "\n",
    "                        max_pooled = get_max_and_concat(box_prev, previous_features, box_cur, features)\n",
    "                        X2.append(max_pooled)\n",
    "                        Y2.append(1 if \"add\" in label[4] else 2)\n",
    "\n",
    "#                         if prev2_features is not None:\n",
    "#                             box_prev2 = prev2_features[\n",
    "#                                 floor(label[0]*previous_features.shape[0]):\n",
    "#                                 ceil(label[2]*previous_features.shape[0]), \n",
    "#                                 floor(label[1]*previous_features.shape[1]):\n",
    "#                                 ceil(label[3]*previous_features.shape[1]),:]\n",
    "\n",
    "#                             max_pooled = get_max_and_concat(\n",
    "#                                 box_prev2, prev2_features,\n",
    "#                                 box_prev, previous_features,\n",
    "#                                 box_cur, features)\n",
    "#                             X3.append(max_pooled)\n",
    "#                             Y3.append(1 if \"add\" in label[4] else 2)\n",
    "\n",
    "\n",
    "                for label in previous_boxes[1]:\n",
    "                    if(\"remove\" in label[4] or \"move_from\" in label[4]):\n",
    "                        box_prev = previous_features[\n",
    "                            floor(label[0]*previous_features.shape[0]):\n",
    "                            ceil(label[2]*previous_features.shape[0]), \n",
    "                            floor(label[1]*previous_features.shape[1]):\n",
    "                            ceil(label[3]*previous_features.shape[1]),:]\n",
    "                        box_cur = features[\n",
    "                            floor(label[0]*features.shape[0]):\n",
    "                            ceil(label[2]*features.shape[0]), \n",
    "                            floor(label[1]*features.shape[1]):\n",
    "                            ceil(label[3]*features.shape[1]),:]\n",
    "\n",
    "                        max_pooled = get_max_and_concat(box_cur, features, box_prev, previous_features)\n",
    "                        X2.append(max_pooled)\n",
    "                        Y2.append(1 if \"remove\" in label[4] else 2)\n",
    "\n",
    "#                 if prev2_boxes is not None:\n",
    "#                     for label in prev2_boxes[1]:\n",
    "#                         if(label[4] == \"remove\"):\n",
    "#                             box_prev = previous_features[\n",
    "#                                 floor(label[0]*previous_features.shape[0]):\n",
    "#                                 ceil(label[2]*previous_features.shape[0]), \n",
    "#                                 floor(label[1]*previous_features.shape[1]):\n",
    "#                                 ceil(label[3]*previous_features.shape[1]),:]\n",
    "#                             box_cur = features[\n",
    "#                                 floor(label[0]*features.shape[0]):\n",
    "#                                 ceil(label[2]*features.shape[0]), \n",
    "#                                 floor(label[1]*features.shape[1]):\n",
    "#                                 ceil(label[3]*features.shape[1]),:]\n",
    "\n",
    "#                             box_prev2 = prev2_features[\n",
    "#                                 floor(label[0]*previous_features.shape[0]):\n",
    "#                                 ceil(label[2]*previous_features.shape[0]), \n",
    "#                                 floor(label[1]*previous_features.shape[1]):\n",
    "#                                 ceil(label[3]*previous_features.shape[1]),:]\n",
    "\n",
    "#                             max_pooled = get_max_and_concat(\n",
    "#                                 box_cur, features,\n",
    "#                                 box_prev, previous_features,\n",
    "#                                 box_prev2, prev2_features)\n",
    "#                             X3.append(max_pooled)\n",
    "#                             Y3.append(1 if \"remove\" in label[4] else 2)\n",
    "\n",
    "            prev2_features = previous_features\n",
    "            prev2_boxes = previous_boxes\n",
    "            previous_features = features\n",
    "            previous_boxes = boxes\n",
    "\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "            print (session, ex)\n",
    "    c_ses += 1\n",
    "    X2 = np.asarray(X2)\n",
    "    Y2 = np.asarray(Y2)\n",
    "    X3 = np.asarray(X3)\n",
    "    Y3 = np.asarray(Y3)\n",
    "\n",
    "#     print(X2.shape, Y2.shape, X3.shape, Y3.shape)\n",
    "#     print (\"progress\", session, \"  : \", c_ses / all_ses)\n",
    "    clear_output()\n",
    "\n",
    "\n",
    "    X2all[session] = X2\n",
    "    X3all[session] = X3\n",
    "    Y2all[session] = Y2\n",
    "    Y3all[session] = Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sessions_path + \"/dataset_prod_new_model_same_add_move_1prev_session_split_bla.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X2all, Y2all], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sessions_path + \"/dataset_prod_new_model_same_add_move_2prev_session_split_bla.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X3all, Y3all], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
